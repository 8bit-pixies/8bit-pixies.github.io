[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Just a machine learning engineer who happens to build models and other stuff."
  },
  {
    "objectID": "posts/gentle-boost/index.html",
    "href": "posts/gentle-boost/index.html",
    "title": "GentleBoost Algorithm",
    "section": "",
    "text": "Often in academic literature, boosting is introduced through AdaBoost or maybe sometimes they jump straight into Gradient Boosting. In this post, I thought I’ll introduce it in a different way, using “Gentle Boosting”, which is far easier to implement and understand.\nIn Python-esque code, Gentle Boost is implemented as follows:\n# with training set, &lt;X, y&gt;\nlearning_penalty = 1/1.1  # a parameter of interest\nw = np.array([1.0 for record in X.shape[0]])\nfor model in models:\n    model.fit(X, y, weights=w)\n    # update w based on error\n    # set record 1 if correctly predicted, -1 if incorrect\n    weight_update_factor = ((y == model.predict(X)) * 2) -1\n    w = w * np.power(learning_penalty, weight_update_factor)\n\n# inference\nnp.mean([model.predict(X) for model in models])\nWhat’s going on here?\n\nWe train the model based on weights of the observation (higher weights of previous model got the prediction wrong, lower weight if the previous model got it correct)\nAt each step we augment the weights by a fixed pre-known penalty, by alpha for correct predictions and 1/alpha for incorrect predictions.\nFor prediction, simply take the average\n\nThis works in the gentle boosting framework by using newton steps to update the weights of the model. By having fixed step sizes for updating the weights it ensures that the weights are bounded and outliers won’t over-weigh the model. The original formulation uses scaling in the form of alpha = exp(1), based on the expoential objective function. In the above formation the scaling is a parameter of the model. This can be interpretted as a modified objective variation to gentle boost instead.\nI think this variation is very simple to understand and implement whilst still being somewhat more effective than not using boosting at all.\nFor more information please see an implementation of Gentleboost and the corresponding writeup."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Maybe its time to “restart” my blog. I’ve actually been blogging for quite a while previously - though it was more adhoc.\nThis blog will place a heightened focus more on engineering and technology - the doing of things.\nHow did I build this blog?\nI decided to use Quarto to build this static blog. It provides a way to combine code outputs in a blog format. Perhaps we want to post research results or outcomes! This is a suitable way to do that."
  },
  {
    "objectID": "posts/suno-bark/index.html",
    "href": "posts/suno-bark/index.html",
    "title": "Generate Podcasts from a Script using Suno Bark!",
    "section": "",
    "text": "Today we’re taking a look at a text to speech library called Suno. Suno can generate realistic audio from a script.\nTo get started, simply install it in the normal way using - pip install as per the git repository instructions.\npip install git+https://github.com/suno-ai/bark.git\nThen to generate the audio, set the voice and download the appropriate weights.\nBy default, Suno only generates sentences that are at most fourteen seconds long. To make it longer, there are some tricks we employ by splitting it up into sentences and artificially adding some silence between the sentences.\nOne way to achieve this is to first split the sentences using nltk, though if the sentences are too long, Suno/Bark has a tendency to unnecessarily elongate the audio.\nYou can see how the script is written and the code to reproduce this audio file in its entirety. In the future I may use this to generate podcasts off written scripts and blog posts automatically!\nimport re\n\nimport nltk\nimport numpy as np\nimport scipy\nfrom tqdm import tqdm\nfrom transformers import AutoModel, AutoProcessor\n\n\nclass TextToSpeech:\n    _processor = AutoProcessor.from_pretrained(\"suno/bark-small\")\n    _model = AutoModel.from_pretrained(\"suno/bark-small\")\n    _sampling_rate = _model.generation_config.sample_rate\n    _silence_in_seconds = 0.25\n\n    @classmethod\n    def _generate_from_sentence(cls, sent):\n        voice_preset = \"v2/en_speaker_9\"\n        inputs = cls._processor(\n            text=[sent],\n            return_tensors=\"pt\",\n            voice_preset=voice_preset,\n        )\n        speech_values = cls._model.generate(**inputs)\n        return speech_values.cpu().numpy().squeeze()\n\n    @classmethod\n    def _export_to_audio(cls, data_array, fname):\n        scipy.io.wavfile.write(fname, rate=cls._sampling_rate, data=data_array)\n\n    @classmethod\n    def generate_audio_from_long_script(cls, script, fname):\n        sentences = nltk.sent_tokenize(re.sub(r\"\\s+\", \" \", script))\n\n        silence = np.zeros(int(cls._silence_in_seconds * cls._sampling_rate))  # quarter second of silence\n\n        pieces = []\n        for sentence in tqdm(sentences):\n            audio_array = cls._generate_from_sentence(sentence)\n            pieces += [audio_array, silence.copy()]\n        data_array = np.concatenate(pieces)\n        cls._export_to_audio(data_array, fname)\n\n\nif __name__ == \"__main__\":\n\n    script = \"\"\"\n    Welcome - today we're taking a look at a text to speech library called Suno. \n    Suno can generate realistic audio from a script.\n\n    To get started, simply install it in the normal way using - \n    pip install as per the git repository instructions.\n    Then to generate the audio, set the voice and download the appropriate weights.\n    The voice that you're currently listening to is english speak number nine.\n\n    By default, Suno only generates sentences that are at most fourteen seconds long.\n    To make it longer, there are some tricks we employ by splitting it up into sentences\n    and artificially adding some silence between the sentences.\n\n    You can see how the script is written and the code to reproduce this audio file in its entirety.\n    In the future I may use this to generate podcasts off written scripts and blog posts automatically!\n    \"\"\"\n\n    TextToSpeech.generate_audio_from_long_script(script, \"podcast.wav\")\nListen to the audio here!\n\n\nYour browser does not support the audio element."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Generate Podcasts from a Script using Suno Bark!\n\n\n\n\n\n\n\ncode\n\n\nai\n\n\n\n\n\n\n\n\n\n\n\nSep 15, 2023\n\n\npixies\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nSep 9, 2023\n\n\npixies\n\n\n\n\n\n\n  \n\n\n\n\nGentleBoost Algorithm\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nSep 9, 2023\n\n\npixies\n\n\n\n\n\n\nNo matching items"
  }
]